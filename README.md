# ðŸ‡®ðŸ‡³ IndiaSpeaks Tamil TTS â€“ Proof of Concept

A lightweight **Text-to-Speech (TTS)** engine generating **natural Tamil speech** for **low-power mobile devices** using a Tacotron-style model trained on a toy dataset.

---

## Objectives

- **Sampling Rate**: 24 kHz  
- **Model Size**: â‰¤ 6 MB  
- **Latency**: â‰¤ 120 ms per sentence on Snapdragon 855  

---

## Folder Structure



TTS\_India\_Speak/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ toy\_tts\_parallel\_data.csv       # Toy parallel dataset
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoints/                    # Model checkpoints (e.g., model\_epoch\_500.pt)
â”‚   â”œâ”€â”€ mel\_outputs/                    # Mel plots from training
â”‚   â”œâ”€â”€ audio\_output/                   # Final WAV files
â”‚   â””â”€â”€ optimized\_model/                # ONNX optimized model
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data\_loader.py                  # Dataset and DataLoader
â”‚   â”œâ”€â”€ model.py                        # TacotronLite model
â”‚   â”œâ”€â”€ train.py                        # Training loop
â”‚   â”œâ”€â”€ infer.py                        # Inference pipeline
â”‚   â”œâ”€â”€ utils.py                        # Griffin-Lim vocoder
â”‚   â”œâ”€â”€ optimization\_model.py           # Full optimization pipeline
â”‚   â””â”€â”€ onnx\_export.py                  # ONNX export logic (called by optimization\_model)
â”œâ”€â”€ README.md                           
```

---

## Setup Instructions

### 1. Create Environment & Install Dependencies

```bash
conda create -n tts_india_speak python=3.10
conda activate tts_india_speak

pip install -r requirements.txt
````

---

## Pipeline: Train â†’ Infer â†’ Optimize â†’ Re-Infer

### Step 1ï¸âƒ£: Train the Model

Train the TacotronLite model on the toy dataset.

```bash
python src/train.py
```

* Checkpoints saved to `outputs/checkpoints/`
* Mel spectrogram plots saved to `outputs/mel_outputs/`

---

### Step 2ï¸âƒ£: Run Inference (Before Optimization)

Generate audio from a Tamil phrase (in Latin script) using the trained model.

```bash
python src/infer.py
```

Change the text input in `infer.py`:

```python
input_text = "à®¨à¯€à®™à¯à®•à®³à¯ à®Žà®ªà¯à®ªà®Ÿà®¿ à®‡à®°à¯à®•à¯à®•à®¿à®±à¯€à®°à¯à®•à®³à¯?"
```

* Output WAV saved to: `outputs/audio_output/tamil_audio.wav`

---

### Step 3ï¸âƒ£: Optimize the Model (Quantization + ONNX Export)

This step uses `optimization_model.py`, which internally calls `onnx_export.py`.

```bash
python src/optimization_model.py
```

* Optimized model is saved to: `outputs/optimized_model/tts_model.onnx`

---

### Step 4ï¸âƒ£: Run Inference with Optimized Model

Use ONNX Runtime or a separate script to load and run the optimized model. You can replace the `infer.py` pipeline with ONNX-based inference if targeting mobile or edge devices.


## Optimization Techniques Used

| Technique            | Purpose                      |
| -------------------- | ---------------------------- |
| Dynamic Quantization | Reduce model size + latency  |
| ONNX Export          | Make model portable          |
| TorchScript Ready    | Mobile deployment compatible |
| Dim Reduction        | Keep model under 6 MB        |

---

## Evaluation Metrics (Internal)

| Metric         | Description                        |
| -------------- | ---------------------------------- |
| MCD            | Mel-Cepstral Distortion            |
| MOS            | Mean Opinion Score (audio quality) |
| Inference Time | Must be â‰¤ 120 ms on Snapdragon 855 |

---

## Future Improvements

* Replace Griffin-Lim for better quality.
* Add multilingual and streaming support.
* Build Web UI using Streamlit or Flask.

---

## Maintained by

**Om Prakash -> Voice AI Team @ IndiaSpeaks**
Building lightweight multilingual speech systems for India.

---